# ğŸ“ Word Recognition System (CRNN + CTC with Transfer Learning)

This project is a **deep learningâ€“based word recognition (OCR) web application** built using **TensorFlow**, **CNN + BiLSTM (CRNN)** architecture, and **CTC decoding**, deployed with a **Flask web interface**.

The system recognizes **single-word images** and converts them into text with significantly improved accuracy and robustness, leveraging **transfer learning**, **data augmentation**, and **deeper sequence modeling**.
It is trained on the **Synth90k (100k) synthetic word dataset**.

---

## âœ… Whatâ€™s New (v0.0.2)

- âœ… **Pretrained VGG16 backbone** (ImageNet weights)
- âœ… Transfer learningâ€“based CRNN architecture
- âœ… Improved generalization with data augmentation
- âœ… Stable **fixed-size RGB input** pipeline
- âœ… Cleaner separation between **training (CTC)** and **inference**
- âœ… Higher accuracy on complex fonts and mixed casing

---

## ğŸš€ Features

- Image-based **single-word recognition**
- **Pretrained VGG16** + **BiLSTM (CRNN)** architecture
- **CTC (Connectionist Temporal Classification)** decoding
- Fixed-size input: `32 Ã— 256 Ã— 3` (RGB)
- Advanced data augmentation:
  - Random brightness & contrast
  - Small-angle rotation (KerasCV)
- Trained on **Synth90k (100k word images)** dataset
- TensorFlow `.keras` production model
- Lightweight **Flask web application**
- Simple HTML + CSS user interface
- Real-time inference on uploaded images

---

## ğŸ§  Model Architecture

### Pipeline Overview

```
Input Image (32 Ã— 256 Ã— 3)
        â†“
Pretrained VGG16 (ImageNet)
        â†“
Intermediate Feature Map (block3_pool)
        â†“
Sequence Reshaping (Width â†’ Time steps)
        â†“
Dense Projection
        â†“
Bidirectional LSTM Ã— 2
        â†“
Dense + Softmax
        â†“
CTC Decoding
        â†“
Predicted Word
```

### Key Details

- Image Height: `32 px`
- Image Width: `256 px`
- Channels: `3 (RGB)`
- Character Set:

    ```
    aâ€“z, Aâ€“Z, 0â€“9
    ```

- Loss Function: `CTC Loss`
- Decoder: Greedy CTC decoding
- Backbone: **VGG16 (ImageNet pretrained)**

---

## ğŸ‹ï¸ Dataset

- **Dataset Name:** Synth90k (Synthetic Word Dataset)
- **Images:** 100,000 word images
- **Labels:** Stored in `labels.txt`
- **Format:**

    ```
    00000.jpg slinking
    00001.jpg REMODELERS
    00002.jpg Chronographs
    ```

The dataset is downloaded automatically using the **Kaggle API**, making it suitable for **Google Colab**.

---

## ğŸ§° Technologies Used

- **Python**
- **TensorFlow / Keras**
- **VGG16 (Transfer Learning)**
- **BiLSTM (CRNN)**
- **CTC Decoding**
- **KerasCV** â€“ Data augmentation
- **Flask** â€“ Web server
- **HTML / CSS** â€“ Frontend UI
- **NumPy**
- **Kaggle API** â€“ Dataset download
- **Google Colab** â€“ Model training

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ main.py                     # Flask application
â”œâ”€â”€ utils.py                    # Image preprocessing & decoding
â”œâ”€â”€ model/
â”‚   â””â”€â”€ synth90k_crnn.keras     # Trained VGG16-CRNN model
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ training_pipeline.ipynb # Model training notebook
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html              # Web UI template
â”œâ”€â”€ static/
â”‚   â””â”€â”€ css/
â”‚       â””â”€â”€ styles.css          # UI styling
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ README.md                   # Project documentation
â”œâ”€â”€ .gitignore
â””â”€â”€ LICENSE                     # MIT License
```

---

## âš™ï¸ Installation & Setup

1. **Clone the repository**:
   ```bash
   git clone https://github.com/Kalana-S/Word-Recognition-System.git
   cd Word-Recognition-System

2. **Create virtual environment (optional)**:
    ```bash
    python -m venv venv
    source venv/bin/activate  # Linux / macOS
    venv\Scripts\activate     # Windows

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt

4. **Run the Flask application**:
   ```bash
   python main.py

- Then Then open your browser at: 
   ```bash
   http://127.0.0.1:5000

---

## ğŸ–¼ï¸ How It Works (Inference)

1. Upload a **word image**
2. Image is resized to `32 Ã— 256` and normalized
3. VGG16 extracts high-level visual features
4. BiLSTM models character sequences
5. CTC decoder converts predictions to text
6. Recognized word is displayed on the UI

---

## ğŸ“Š Sample Predictions

| Ground Truth | Prediction |
| ------------ | ---------- |
| proctoring   | proctoring |
| miffs        | miffs      |
| Plaguing     | Plaguing   |
| Jag          | Jag        |

The model performs well even with:
- Mixed casing
- Long words
- Complex fonts
- Noisy synthetic samples

---

## âš ï¸ Limitations

- Designed for **single-word images only**
- Not optimized for full-line or paragraph OCR
- No language model (yet)

---

## ğŸ§­ Versioning

| Version | Description                                        |
| ------- | -------------------------------------------------- |
| v0.0.1  | Baseline CRNN + CTC OCR system                     |
| v0.0.2  | Transfer learning, augmentation, improved accuracy |

---

## ğŸ¥ App Demo (Screen Recording)

Full app workflow â€” UI â†’ Input â†’ Prediction<br>

https://github.com/user-attachments/assets/8688c6f2-be0b-48f7-8599-cdc5ce128c48

---

## ğŸ¤ Contribution

Contributions are welcome.

- Fork the repository
- Create a feature branch
- Submit a pull request

---

## ğŸ“œ License

This project is licensed under the **MIT License** <br>
See the `LICENSE` file for details.
