{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee776c-ebf0-412c-8785-8099e9d5fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opendatasets -q\n",
    "!pip install -q keras-cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf2a66-57e6-41be-ab83-d24bbab9e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import opendatasets as od\n",
    "import keras_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a50d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.download(\"https://www.kaggle.com/datasets/allahhitler/ocr-synthetic-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b15c9-a1d8-43c6-b6e9-f60f20a0350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/content/ocr-synthetic-dataset\"\n",
    "IMG_DIR = os.path.join(DATA_ROOT, \"images\")\n",
    "LABEL_FILE = os.path.join(DATA_ROOT, \"labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5bb84-e3a9-4e96-8cc8-92eda5b7b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Images:\", len(os.listdir(IMG_DIR)))\n",
    "\n",
    "with open(LABEL_FILE) as f:\n",
    "    for _ in range(5):\n",
    "        print(next(f).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53551bcb-ec53-4cb3-ae51-ddfd5e960e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0abd0-9426-4332-b90b-5bccdfab6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary\n",
    "\n",
    "CHARS = list(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\")\n",
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=CHARS, mask_token=None, oov_token=None)\n",
    "num_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary()[1:], invert=True)\n",
    "NUM_CLASSES = len(char_to_num.get_vocabulary()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f04b5-cc54-4622-9264-6b8c40c99f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image & Label Processing\n",
    "\n",
    "def load_image(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "def encode_label(text):\n",
    "    chars = tf.strings.unicode_split(text, \"UTF-8\")\n",
    "    return char_to_num(chars)\n",
    "\n",
    "# Consolidated Dataset Function\n",
    "def make_dataset(samples, training=True):\n",
    "    paths = [s[0] for s in samples]\n",
    "    labels = [s[1] for s in samples]\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    def process(p, l):\n",
    "        img = load_image(p)\n",
    "        if training:\n",
    "            img = tf.image.random_brightness(img, 0.2)\n",
    "            img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        return {\"image\": img, \"label\": encode_label(l)}\n",
    "\n",
    "    ds = ds.map(process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Standard batching\n",
    "    ds = ds.padded_batch(\n",
    "        BATCH_SIZE,\n",
    "        padded_shapes={\"image\": [IMG_HEIGHT, IMG_WIDTH, 3], \"label\": [None]}\n",
    "    )\n",
    "\n",
    "    if training:\n",
    "        ds = ds.shuffle(1000)\n",
    "        # Apply geometric augmentations via KerasCV\n",
    "        augmenter = keras_cv.layers.RandomRotation(factor=0.02, fill_mode=\"nearest\")\n",
    "        ds = ds.map(lambda x: {\"image\": augmenter(x[\"image\"]), \"label\": x[\"label\"]},\n",
    "                    num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa6368-4bdb-407a-9970-2560414841cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "\n",
    "def parse_labels(label_file):\n",
    "    samples = []\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2: samples.append((os.path.join(IMG_DIR, parts[0]), parts[1]))\n",
    "    return samples\n",
    "\n",
    "samples = parse_labels(LABEL_FILE)\n",
    "np.random.shuffle(samples)\n",
    "split = int(0.9 * len(samples))\n",
    "train_ds = make_dataset(samples[:split], True)\n",
    "val_ds = make_dataset(samples[split:], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0993f5d-b676-429c-8376-1b52b0f4b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning CRNN\n",
    "\n",
    "def build_crnn():\n",
    "    inputs = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "    base_model = tf.keras.applications.VGG16(\n",
    "        input_tensor=inputs,\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "\n",
    "    x = base_model.get_layer(\"block3_pool\").output\n",
    "\n",
    "    feature_dim = x.shape[1] * x.shape[3]\n",
    "    x = tf.keras.layers.Reshape(target_shape=(-1, feature_dim))(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "    return tf.keras.Model(inputs, outputs, name=\"vgg_crnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93a75a-9ce4-432f-96cb-5c0ff7c60e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTC Training Logic\n",
    "\n",
    "class CTCModel(tf.keras.Model):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        return self.backbone(inputs, training=training)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        images, labels = data[\"image\"], data[\"label\"]\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self.backbone(images, training=True)\n",
    "            batch_size, time_steps = tf.shape(preds)[0], tf.shape(preds)[1]\n",
    "            input_len = tf.fill([batch_size, 1], time_steps)\n",
    "            label_len = tf.math.count_nonzero(labels, axis=1, keepdims=True)\n",
    "            loss = tf.keras.backend.ctc_batch_cost(labels, preds, input_len, label_len)\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        return {\"loss\": tf.reduce_mean(loss)}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        images, labels = data[\"image\"], data[\"label\"]\n",
    "        preds = self.backbone(images, training=False)\n",
    "        batch_size, time_steps = tf.shape(preds)[0], tf.shape(preds)[1]\n",
    "        input_len = tf.fill([batch_size, 1], time_steps)\n",
    "        label_len = tf.math.count_nonzero(labels, axis=1, keepdims=True)\n",
    "        loss = tf.keras.backend.ctc_batch_cost(labels, preds, input_len, label_len)\n",
    "        return {\"loss\": tf.reduce_mean(loss)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d727d-8dd6-43a2-926d-a9ba9e071770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and Train\n",
    "\n",
    "backbone = build_crnn()\n",
    "model = CTCModel(backbone)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38508171-e236-4be0-a06a-5685da8f3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding (GREEDY)\n",
    "\n",
    "def decode(pred):\n",
    "    batch_size, time_steps = tf.shape(pred)[0], tf.shape(pred)[1]\n",
    "    input_len = tf.fill([batch_size], time_steps)\n",
    "    decoded, _ = tf.keras.backend.ctc_decode(pred, input_len, greedy=True)\n",
    "    texts = []\n",
    "    for seq in decoded[0]:\n",
    "        seq = tf.boolean_mask(seq, seq != -1)\n",
    "        text = tf.strings.reduce_join(num_to_char(seq)).numpy().decode()\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "for batch in val_ds.take(1):\n",
    "    preds = backbone(batch[\"image\"], training=False)\n",
    "    texts = decode(preds)\n",
    "    for i in range(5):\n",
    "        gt = tf.strings.reduce_join(num_to_char(batch[\"label\"][i])).numpy().decode()\n",
    "        print(f\"GT: {gt} | PRED: {texts[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc7ad7-f695-46a2-8528-13149a97d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.save(\"File_Path_For_Model_Saving/synth90k_crnn.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
